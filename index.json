[{"authors":["admin"],"categories":null,"content":"Hello, I\u0026rsquo;m Carlvin, a lover of data.\nMy main skills are data analysis; including manipulation and visualization, statitics and predictive modeling. As a quantitative analyst, I develop and test existing to new models for financial markets analysis. I can work with R, Python, F# and the Microsoft Azure machine learning platform.\nIn the night, I love to analyze data, create visualizations to extract meaningful insights and explore different statistical concepts and their applications in real world problems.\nThis is my website and or blog, here you will find my research work in posts, talks I partake in and my data science projects. Feel free to read, comment or offer new suggestions.\n","date":1590710400,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1590828418,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Hello, I\u0026rsquo;m Carlvin, a lover of data.\nMy main skills are data analysis; including manipulation and visualization, statitics and predictive modeling. As a quantitative analyst, I develop and test existing to new models for financial markets analysis. I can work with R, Python, F# and the Microsoft Azure machine learning platform.\nIn the night, I love to analyze data, create visualizations to extract meaningful insights and explore different statistical concepts and their applications in real world problems.","tags":null,"title":"Carlvin J Mwange","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026#34;Courses\u0026#34; url = \u0026#34;courses/\u0026#34; weight = 50 Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026#34;Docs\u0026#34; url = \u0026#34;docs/\u0026#34; weight = 50 Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1567850988,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567850988,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I\u0026rsquo;ll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567850988,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":"Slides can be added in a few ways:\n Create slides using Academic\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567850988,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Carlvin J Mwange"],"categories":["R","Data Visualization"],"content":"\r\rI got bitten by the famous procrastination bug earlier this year, so I missed out on #TidyTuesday‚Äôs week 3(2020) challenge. As a make-up, I thought I should do it here instead and maybe someone will learn one or two things about security, digital privacy to be precise.\n\r\nIntroduction\rExposing ourselves to cyber attacks comes as easy as having access to the internet. Almost every website you visit will require you to create an account to be able to access significant information or services from them - So where exactly does the problem with password strength begin? Memory methinks‚Ä¶\nThe whole purpose of memory is to preserve information. Events, names, faces, mathematical formulas etcetera, all seem recognizable every time we recollect because the mind memorizes them. I don‚Äôt know how exactly remembering works, but you will agree with me on this; the memory is sometimes very unreliable when it comes to cramming passwords. It is for this very reason that, in the quest for memorizing our passwords, we find ourselves using weak passwords.\nDifferent folk memorize passwords differently; some of us share passwords across platforms (very counter intuitive if you actually think about it re cyber security), some use personal information such as names, birthdays, pet names üòÜ and what have you. My point is, we cannot fully trust ourselves to match brute force algorithms trying to hack their way into our Facebook(s), Instagram(s) and worse for me, online banking and credit card accounts. So here are a few Ps and Qs for setting up passwords.\n\rA small challenge for you here, check how long it would take a computer to crack your bank account password.\n\rI used #TidyTuesday‚Äôs passwords data with some more compromised passwords from kaggle for illustration. To keep it concise, all the code used in this post can be found here. Shout out to my good friend and avid data analyst Martin who helped in building a password strength meter used in ranking passwords used here, you can read more on the tool here. That being said, let‚Äôs get visual.\n\n\rSkimming through the data\rThe graph bellow shows a scattered distribution of a small fraction of our compromised passwords. You want to ensure that if your passwords get parsed through this chart, they are on the bottom, far left of the chart i.e, the passwords are unique and exhibit stronger strengths. That way, you know that even a computer will take quite some time before cracking it. The further and lower it is along the x-axis,the smaller it should be to indicate uniqueness and the stronger it is hence the green color.\nOn the contrary, we have quite a lot of passwords clustered in between 0-35 on the strength meter. If you look at those passwords, it should be quite obvious that they‚Äôre weak. This would explain why we have them here as our data. This chart shows most of the aspects of a password that I‚Äôll be discussing below.\n\n\rCreating secure passwords\r#1.Don‚Äôt share passwords\rI mean, think about your bank accounts if your excuse is ‚ÄúI don‚Äôt have any vital information on me anyway‚Äù. Every time you share passwords across platforms, you make life easier for an attacker. Chances are this shared password is really strong and so you might think, why not? But here‚Äôs the catch, a wise hacker understands that you might have done this, and all he has to do is gain access to that account you think has no information about you and look for an identity. With this little precious piece of information, it‚Äôs easier for them to try out the accounts you know are actually important. Bank accounts and online shopping cards could tell you this if they were human.\n\r#2.Regularly change your passwords\rFirst of all, if you‚Äôre too lazy to change a default password that some sites offer newbies, you deserve to be hacked. Start by creating a password of your own. Every now and then, you want to review and update your passwords because hackers are improving on a daily too.\n\r#3.Personal information is a plea to be hacked\rI remember using my own name on MySpace for a password, good days those ones. Times have changed and so should you. Hackers who guess passwords start basic. Your name will be first, then popular pet names because they saw you pause with your chicken on Facebook. To put it in perspective, here‚Äôs how cute you look to hackers when you use your personal information as passwords. Same goes for using dictionary words for passwords.\n\r\r\rFigure 1: The challenge\r\r\r\r\n\r#4. Longer passwords are safer passwords\rVariable Distributions\rHere we have another plot showing distribution of our passwords based on length.\n\n\r\r#5. 2FA is your friend, use it\rTwo-factor authentication offers an extra protection to your accounts. In an event someone cracks your password, they will require a security code to gain access to the account. This code is usually sent to a mobile number registered to the said account, one cannot access the account without keying in the right code. Have it enabled if it‚Äôs available.\n\r\r\rSource: comics\r\r\r\r\n\rMuch as it‚Äôs possible to do all these on your own, a password manager is your best shot. With a password manager, you only have to worry about one master password. A password manager stores all your sensitive passwords for you, runs frequent checks on them and generates new stronger passwords for you as well, that way your memory won‚Äôt fail you. Most password managers automatically recognize a website whenever visited and will automatically fill in your credentials. I personally use the free version of Lastpass, there are many more which are entirely free or on subscription basis. You can read more about them here. I‚Äôm out üòÑ.\n\r\n\r\r\n\r\r","date":1590710400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590828418,"objectID":"c9faf89d383083c7eb987d2350891f30","permalink":"/post/password-etiquette/","publishdate":"2020-05-29T00:00:00Z","relpermalink":"/post/password-etiquette/","section":"post","summary":"Lessons and observations from week 3 of 2020's #TidyTuesday challenge","tags":["TidyTuesday","R","Data Visualization"],"title":"Password Etiquette","type":"post"},{"authors":null,"categories":["Twitter","Data Visualization"],"content":"\r\rFirst #TidyTuesday contribution for the year, still have a lot to catch up on clearly. I made a leaflet map from a blog post on https://t.co/wTAS19lPLv . Stuck at sharing the interactive html file for now. Code: https://t.co/2inpMWZfuB pic.twitter.com/e6SIl02Z8M\r‚Äî Professional Griefer (@PipeFunction) January 30, 2020\r\r\r\r\rPerfect timing for @dataandme's tweet‚Ä¶I decided to use {reactable} for this week's #TidyTuesday challenge. Showing average bird rating against number of votes. Still stuck at embedding the bird images though, to be continued‚Ä¶ #rstats Code: https://t.co/FlFyoZKSa8 pic.twitter.com/Dsg86QBwqM\r‚Äî Professional Griefer (@PipeFunction) November 20, 2019\r\r\r\r\rMy contribution to this week's #TidyTuesday Grouped movies by quarter of the year they were released, Q4 movies have a slightly higher rating. Budgets don't always guarantee viewer success‚Ä¶Also, I just learnt I haven't watched Psychedelia yet #rstats #datavisualization pic.twitter.com/MT5NgkttW1\r‚Äî Professional Griefer (@PipeFunction) October 23, 2019\r\r\r\r\rTried out a Sankey plot for this week's #TidyTuesday data‚Ä¶ Distribution of gender across age groups, body weight, and equipment used for Squat-Bench-Deadlift events. Code: https://t.co/6HLl7z6wzp #rstats #dataviz pic.twitter.com/5dcSGYHZ1H\r‚Äî Professional Griefer (@PipeFunction) October 9, 2019\r\r\r\r\rTried out a spaghetti plot for this weeks #TidyTuesday , reducing the unit_type to my own based on a few common features‚Ä¶ Quick one, is it that there are very few accessible (they also started in the 50s-60s) parks with water bodies or guys just don't visit them? pic.twitter.com/yTmsplg41R\r‚Äî Professional Griefer (@PipeFunction) September 17, 2019\r\r\r\r\rFirst of many contributions to #TidyTuesday. The US and USSR were responsible for over 80% of explosions. Random fact; After rejecting the CTB treaty in, Pakistan tests six nuclear weapons, 1998 in response to India‚Äôs tests. code:https://t.co/nRM78MBSc1 #dataviz #rstats #ggplot2 pic.twitter.com/ZiXUzf7fZn\r‚Äî Professional Griefer (@PipeFunction) August 20, 2019\r\r\r\r\rAn update based on @CedScherer 's suggestion. Using the maximum value actually shows the true trend in percentage change while solving the overlaps issue. Mean skews the data hence not recommended‚Ä¶this plot here a better representation. #TidyTuesday #rstats #DataVisualization pic.twitter.com/Nk4VqXG8TB\r‚Äî Professional Griefer (@PipeFunction) September 6, 2019\r\r\r\r\rMoore's Law: Focused on Intel CPUs,% change in the avg no. of transistors yearly shows the exponential growth trend. However, the % change has been reducing over recent yrs. ‚ÄúIt's the nature of exponential functions, they eventually hit a wall‚Äù- Moore (2005) #TidyTuesday #rstats pic.twitter.com/LngIYw9GtX\r‚Äî Professional Griefer (@PipeFunction) September 5, 2019\r\r\r\r\rHighlighting top 1000 nukes by yield, Bravo yielded the most megatons:15 followed by Yankee: 13.5 mt , Romeo:11 mt , Mike:10.4 mt , Handley:10 mt . All were US's , mostly deployed in Bikini‚Ä¶apart from Hanley which was UK's #rstats #TidyTuesday #dataviz pic.twitter.com/c9KnQGaUiH\r‚Äî Professional Griefer (@PipeFunction) August 21, 2019\r\r\r\r\r","date":1567987200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580418154,"objectID":"4c1271fdc7de54951ea7a71461f4f9c5","permalink":"/project/tidy-tuesday/","publishdate":"2019-09-09T00:00:00Z","relpermalink":"/project/tidy-tuesday/","section":"project","summary":"A collection of my data visualization contributions to the TidyTuesday weekly social project","tags":["Twitter","Data Visualization"],"title":"Tidy Tuesday","type":"project"},{"authors":["Carlvin J Mwange"],"categories":["R","Data Visualization"],"content":"\r\r‚ÄúThe goal is to turn data into information and information into insight.‚Äù ‚Äì Carly Fiorina, former chief executive officer, Hewlett Packard.\n\rINTRODUCTION\rIf you are familiar with data analysis then I‚Äôm certain that you fully relate to the above statement. After all, it would be pointless to play around with lots of data just for the love of it, sometimes not but you get the point.\nData is gold, and the more you have the better off you are. However, raw unprocessed data is of no use unless you manipulate and gain insights from it. Before embarking on say statistical modelling and visualization of your data, it is very important to first have an understanding of the data itself. Exploratory Data Analysis (EDA) aids in visualization, transformation, and generally cleaning or remodeling data before diving deep into information extraction.\nThere are no set rules to be followed when performing EDA. As a data preparation phase, one is allowed to decide what suits them best in order to gain an understanding of their data. However, there are two most important questions one should seek to answer while studying their data:\n\rIs there variation within my variables?\rIs there any correlation between my variables?\r\rThat being said, EDA involves the following checks among others:\n\rDescriptive Statistics - Gives a summarized understanding of the data, usually as measures of central tendency and variability.\r\rMean - Arithmetic average\rMedian - middle value\rMode - most frequent value\rStandard Deviation - variation from the mean\rKurtosis -peakedness of the data distribution\rSkewness - symmetry of the data distribution\r\rGroupings of data\rMissing values\rANOVA: Analysis of variance\rGraphical visualization, not restricted to:\r\rHistogram -frequency bar plots\rDensity estimation - an estimation if the frequency distribution based on sample data\rBox plots - A visual representation of median, quantiles, symmetry and ourtliers\rScatter plots - a graphical display of variables plotted on the x and y axes.\r\r\rIn this post, we will perform EDA on a sample data set containing responses to a mobile banking survey in Kenya. If you would like to follow along with the same data, you can download it here.\n\rData Importation\rThe code chunk below imports our data set into R.\n#Loading Data into R toc_depth: 2\rmobileBanking.Df \u0026lt;- read.csv(\u0026quot;J://Personalprojects//Blogsite//data//MobileBankinginKenya.csv\u0026quot;, header = TRUE, stringsAsFactors = FALSE )\rmobileBanking.Df \u0026lt;- mobileBanking.Df[,-1] #Remove the number column which is Irrelevant\r1.0.0 Data Inspection\rOnce our sample data set is loaded, we check for features present. We first need to load all the libraries needed for data analysis and manipulation.\n #Load required packages or install if not present.----\rload.libraries \u0026lt;- c(\u0026#39;data.table\u0026#39;,\u0026#39;tidyverse\u0026#39;,\u0026#39;gridExtra\u0026#39;, \u0026#39;corrplot\u0026#39;, \u0026#39;GGally\u0026#39;, \u0026#39;ggplot2\u0026#39;, \u0026#39;e1071\u0026#39;, \u0026#39;dplyr\u0026#39;)\rinstall.lib \u0026lt;- load.libraries[!load.libraries %in% installed.packages()]\rfor(libs in install.lib) install.packages(libs, dependences = TRUE)\r#Load libraries and flag TRUE\rsapply(load.libraries, require, character = TRUE)\rThe function above takes in a list of required libraries, checks if they are already installed and installs them if not. It then loads all the packages one at a go.\n\r\r\rFigure 1: Loaded packages\r\r\r\r\r1.1.0 Observing the data structure\rdim(mobileBanking.Df)\r## [1] 43 11\rThe data set has 43 rows with 11 Variables. We therefore explore the data types of each variable/column.\n#Check Categorical VS Numeric Characters----\rcat_vars \u0026lt;- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.character))]\rcat_vars\r## [1] \u0026quot;Gender\u0026quot; \u0026quot;Age.Range\u0026quot; ## [3] \u0026quot;Have.Bak.Account\u0026quot; \u0026quot;Bank.account.connected.to.MB\u0026quot;\r## [5] \u0026quot;MB.used.for\u0026quot; \u0026quot;Importance\u0026quot; ## [7] \u0026quot;Benefit\u0026quot; \u0026quot;Bank.Visit\u0026quot; ## [9] \u0026quot;MB.Safety\u0026quot; \u0026quot;Influence\u0026quot; ## [11] \u0026quot;Satisfaction\u0026quot;\rnumeric_vars \u0026lt;- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.numeric))]\rnumeric_vars\r## character(0)\rTo identify the data types, we can check for numeric and categorical variables present in the data. In our case, all the variables in our data set are categorical. We will therefore explore the data from a categorical approach rather than numeric. There exists different visualization methods for different data types. Now that we have established the general structure of the data, we can check for missing values, NAs.\n#Checking data for any missing values\rcolSums(sapply(mobileBanking.Df, is.na))\r## Gender Age.Range ## 0 0 ## Have.Bak.Account Bank.account.connected.to.MB ## 0 0 ## MB.used.for Importance ## 0 0 ## Benefit Bank.Visit ## 0 0 ## MB.Safety Influence ## 0 0 ## Satisfaction ## 0\rWe have no columns with missing values in our data. We can therefore proceed to analysis without worrying about missing values. In a case whereby there exists NA values, one can choose whether to replace the nulls with the most appropriate values or remove the rows with nulls from the data. This is important for later stages of analysis that include data modelling, like Machine Learning.\n\n\r1.1.1 Data Summary\r#Data Summary----\rsummary(mobileBanking.Df)\r## Gender Age.Range Have.Bak.Account ## Length:43 Length:43 Length:43 ## Class :character Class :character Class :character ## Mode :character Mode :character Mode :character ## Bank.account.connected.to.MB MB.used.for Importance ## Length:43 Length:43 Length:43 ## Class :character Class :character Class :character ## Mode :character Mode :character Mode :character ## Benefit Bank.Visit MB.Safety ## Length:43 Length:43 Length:43 ## Class :character Class :character Class :character ## Mode :character Mode :character Mode :character ## Influence Satisfaction ## Length:43 Length:43 ## Class :character Class :character ## Mode :character Mode :character\r\nThe base R Summary() function comes in handy at summarizing data. In our case, there is no statistical measures since all our variables are categorical. Note that the function also specifies the specific data types. There are more than enough ways to inspect data structures in R.\n\n\r2.0.0 Getting Insights from the data\r2.1.0 Descriptive Statistics For Categorical Data\rThe main goal of descriptive statistics is to inform data analysts on the main features of either numerical or categorical data, using sample summaries represented as either tables, individual numbers or charts and graphs. Since we only have categorical data, I will illustrate the most used forms of descriptive statistics for the same. However, like I mentioned earlier, there are more than enough ways to analyze data in R.\n\n2.1.1 Frequencies\rFrequencies illustrate the number of occurrences or observations of a particular category in data. We use contigency tables to present this information. In R this can be achieved using the table() function.\nFrom out data, the total distribution of respondents based on gender looks like this;\n#Gender frequencies\r#library(kableExtra)\rtable(mobileBanking.Df$Gender)\r## ## Female Male ## 20 23\rWe can illustrate multiple attributes using cross classification tables such as;\n#library(kableExtra)\r# Cross classification counts for gender by Mobile banking safety opinion\rtable(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety)\r## ## NotAtAll Somewhat Very\r## Female 3 11 6\r## Male 0 19 4\rMultidimensional tables with three or more categories can also be achieved using the ftable() . As an example, let‚Äôs check out the number of respondents based on gender, mobile banking safety opinion and how often they visit the bank.\n#Counts by gender, opinion and bank visits\rtable_ \u0026lt;- table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety, mobileBanking.Df$Bank.Visit)\rftable(table_)\r## FewTimesAyear OnceMonth\r## ## Female NotAtAll 3 0\r## Somewhat 11 0\r## Very 5 1\r## Male NotAtAll 0 0\r## Somewhat 15 4\r## Very 4 0\r\n\r2.1.1 Proportions\rProportions are basically contingency tables represented as percentages. From our previous tables, we can do proportions for the same by applying prop.table() to output produced by the *table() function. Proportions for the above will then be;\n#library(kableExtra)\r#Gender frequencies proportions\rprop.table(table(mobileBanking.Df$Gender))\r## ## Female Male ## 0.4651163 0.5348837\r#Percentage idistribution for Gender by mobile banking safety\rprop.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety))\r## ## NotAtAll Somewhat Very\r## Female 0.06976744 0.25581395 0.13953488\r## Male 0.00000000 0.44186047 0.09302326\r#Percentage by gender, opinion and bank visits, rounding off to 2 decimal places\rtable_ \u0026lt;- table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety, mobileBanking.Df$Bank.Visit)\rftable(round(prop.table(table_),2))\r## FewTimesAyear OnceMonth\r## ## Female NotAtAll 0.07 0.00\r## Somewhat 0.26 0.00\r## Very 0.12 0.02\r## Male NotAtAll 0.00 0.00\r## Somewhat 0.35 0.09\r## Very 0.09 0.00\r\n\r2.1.2 Marginals\rMarginals measure counts across columns or rows in a contingency table. Margin.table() gives us the frequencies while prop.table() gives us the percentages. Using our previous examples on frequencies;\n# FREQUENCY MARGINALS\r# row marginals - totals for each gender across mobile banking opinion\rmargin.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), 1)\r## ## Female Male ## 20 23\r# colum marginals - totals for each gender across mobile banking opinion\rmargin.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), 2)\r## ## NotAtAll Somewhat Very ## 3 30 10\r# PERCENTAGE MARGINALS\r# row marginals - row percentages across gender\rprop.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), margin = 1)\r## ## NotAtAll Somewhat Very\r## Female 0.150000 0.550000 0.300000\r## Male 0.000000 0.826087 0.173913\r# colum marginals - column percentages acrossmobile banking opinion\rprop.table(table(mobileBanking.Df$Gender, mobileBanking.Df$MB.Safety), margin = 2)\r## ## NotAtAll Somewhat Very\r## Female 1.0000000 0.3666667 0.6000000\r## Male 0.0000000 0.6333333 0.4000000\r\r\r2.2.0 Visualizing Distributions\rThe code chunk bellow is a function that takes in our data set and plots all the present variables in it. Since we have categorical variable only, we will use bar plots for visualization. They are the most appropriate for categorical data.\n#Loading Data into R toc_depth: 2\rmobileBanking.Df \u0026lt;- read.csv(\u0026quot;J://Personalprojects//Blogsite//data//MobileBankinginKenya.csv\u0026quot;, header = TRUE, stringsAsFactors = FALSE )\rmobileBanking.Df \u0026lt;- mobileBanking.Df[,-1] #Remove the number column which is Irrelevant\r#Check Categorical VS Numeric Characters----\rcat_vars \u0026lt;- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.character))]\rnumeric_vars \u0026lt;- names(mobileBanking.Df)[which(sapply(mobileBanking.Df, is.numeric))]\r####Convert character to factors----\rlibrary(data.table)\rsetDT(mobileBanking.Df)[,(cat_vars) := lapply(.SD, as.factor), .SDcols = cat_vars]\rmobileBanking.Df_cat \u0026lt;- mobileBanking.Df[,.SD, .SDcols = cat_vars]\r##mobileBanking.Df_cont \u0026lt;- mobileBanking.Df[,.SD,.SDcols = numeric_vars]\r#Functions for Plots---\rlibrary(ggplot2)\rlibrary(gridExtra)\rplotHist \u0026lt;- function(data_in, i) {\rdata \u0026lt;- data.frame(x=data_in[[i]])\rp \u0026lt;- ggplot(data=data, aes(x=factor(x))) + stat_count() + xlab(colnames(data_in)[i]) + theme_light() + theme(axis.text.x = element_text(angle = 90, hjust =1))\rreturn (p)\r}\rdoPlots \u0026lt;- function(data_in, fun, ii, ncol=3) {\rpp \u0026lt;- list()\rfor (i in ii) {\rp \u0026lt;- fun(data_in=data_in, i=i)\rpp \u0026lt;- c(pp, list(p))\r}\rdo.call(\u0026quot;grid.arrange\u0026quot;, c(pp, ncol=ncol))\r}\rplotDen \u0026lt;- function(data_in, i){\rdata \u0026lt;- data.frame(x=data_in[[i]], SalePrice = data_in$SalePrice)\rp \u0026lt;- ggplot(data= data) + geom_line(aes(x = x), stat = \u0026#39;density\u0026#39;, size = 1,alpha = 1.0) +\rxlab(paste0((colnames(data_in)[i]), \u0026#39;\\n\u0026#39;, \u0026#39;Skewness: \u0026#39;,round(skewness(data_in[[i]], na.rm = TRUE), 2))) + theme_light() return(p)\r}\r\n\rVariable Distributions\r#Plotting categorical values----\r#Bar plots\rdoPlots(mobileBanking.Df_cat, fun = plotHist, ii = 1:4, ncol = 2)\r\n\rGender\rIt can be seen that a larger number of respondents were male, this is however by a small margin. If we had a larger data set we could have more female respondents.\n\n\rAge Range\rA majority of respondents were younger guys between age 21-30, followed by the 31-40 age bracket. The least respondents were those above age 41. This could be probably because the older people chose not to participate in the survey as opposed to the younger ones, or that they somehow never got to opportunity to do so. A good example is the medium by which the survey was conducted, which the older people didn‚Äôt have.\n\n\rHave Bank Account \u0026amp; Linked To Mobile Banking\rAll the respondents had bank accounts. A very small number had their business bank accounts linked to mobile banking. Majority had linked their current accounts probably due to the convenience that comes with mobile banking like frequent or timeless withdrawals.\n\n\n\rUses Of Mobile Banking, Importance And Benefits\rMost respondents use mobile banking services for making payments. This is followed by cash withdrawals. Airtime purchase and money transfer happen to be the least uses for the service. This could be because they are easily accessible needs unlike cash withdrawal and making payments in terms of mobility convenience.\nMost respondents found mobile banking services very important, probably owing to the affordable cost charges and good service which could mean less usability issues when using the services.\n\n\n\rBank Visits\rWe had most users who visit their banks a few times a year while the least do it once a month. This means that generally, fewer people visit the bank physically. This could be a major impact of mobile banking services.\n\n\rMobile Banking Safety, Influence And Satisfaction\rDespite being majorly satisfied by the services, most respondents did not find mobile banking services very safe. It is also seen as time saving which is probably why we had very few bank visits in general.\n\n\r\r\rConclusion from variable distributions\rIt can be concluded that mobile banking is mainly preferred by younger people, a majority being of the male gender. However, the only benefit most users find from mobile banking seems to be the convenience it brings. Safety is still a major concern.\n\n\rThat‚Äôs basically it for exploratory data analysis. I made sure to cover the basics, meaning there‚Äôs still much to be added on to this; more visualizations, packages that simplify the whole process etc‚Ä¶This is to be continued. For a detailed documentation on the same, here‚Äôs Hadley Wickham‚Äôs R for Data Science book you can use as a reference point.\n\r\n\r\r\n\r","date":1564876800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576001886,"objectID":"ab9cbfadd2fa5bd2f4fd8d6a895b7e94","permalink":"/post/exploratory-data-analysis/","publishdate":"2019-08-04T00:00:00Z","relpermalink":"/post/exploratory-data-analysis/","section":"post","summary":"Basics for data preparation","tags":["Twitter","R","Data Visualization"],"title":"Exploratory Data Analysis","type":"post"},{"authors":null,"categories":["Data Visualization"],"content":"\rMotivation\rThis project contains links to my developed shiny apps you might find helpful‚Ä¶For every new interesting idea I have I‚Äôll build an app. Some might be basic shiny, others might be complex shiny, depending on how important I think they are. Let me know what you think,suggestions for improvements and new apps are welcome.\n1. Live time progress A live time visualizing app with a stop watch for board games hosted in ShinyApp.io\n\r","date":1560038400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568756055,"objectID":"4499134db9bf85a272b616030d79d022","permalink":"/project/shiny-apps/","publishdate":"2019-06-09T00:00:00Z","relpermalink":"/project/shiny-apps/","section":"project","summary":"A curated list of web apps, built in R's Shiny","tags":["Data Visualization"],"title":"Handy Shiny Apps","type":"project"},{"authors":["Carlvin J Mwange"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567850988,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":["Carlvin J Mwange"],"categories":["Data Mining","Machine Learning"],"content":"\rIntroduction:\rHere‚Äôs a fun fact; An average human being (probably an adult) makes close to 30,000 conscious decisions every day. This isn‚Äôt entirely true though, in fact, I just made that number up. I could be right because if you think about it, how many decisions would you say you make on a day to day basis? Depending on who you are the above obviously varies widely and you know best. We all make n decisions every day- what to do, eat, buy or hit. The real question however is, do our daily choices solely depend on our consciousness? Are there any other factors at hand that influence our decision making process? Are all these factors, if any, always straight forward choices or do we sometimes get ‚Äúnudged‚Äù into these choices we make?\nNudge theory basically states that; by understanding how people think and what drives their decisions, we can use those factors to steer them into making decisions differently, through positive reinforcement. Research has shown that, by presenting choices differently rather than in a legislative manner, people can be influenced into making specific desired choices. This theory is widely used in behavioral economics by presenting subtle nudge units intended to influence people‚Äôs thoughts about financial products. The theory was however initially more of a moral aspect meant to help people make better decisions in life and not as a tool for commercial gain. Over years of practice, different applications of the theory emerged.\nNow that we have a basic understanding of what nudge theory is about, we can explore an applicable example. This post mainly focuses on a short research project I happened to be part of, actually my first hackathon experience hosted by Safaricom PLC. Let‚Äôs dive in!\nThe Challenge\rThis photo a team mate took at the hackathon contains a problem statement for the challenge:\n\r\r\rFigure 1: The challenge\r\r\r\r\r\rTools used:\rOur twitter data was fetched using R, I have done a post on setting up a twitter API to fetch twitter data here. R has several packages (such as ‚ÄútweeteR‚Äù and ‚Äúrtweet‚Äù) that one can use to stream data from twitter. Our data cleaning and pre-processing was mainly done in Python.\n\rNote: To keep this post concise, code for the workings has been minimized. The source code for this post can be found here, for anyone interested in trying out the same process. The code is well commented for easier understanding as well.\n\r1.Fetching Data\rThe team agreed on a few terms to query data on from twitter. For an unbiased range of topics, we settled on fetching tweets under trending topics and a few more from random words. We had tweets from or containing the following:\n\r#MenConference2019\n\r‚ÄúHere‚Äù\n\r#r_Stats\n\r‚ÄúPWC‚Äù\n\r#Friday Feeling\r\rA total of 7000 tweets were captured. The data frame had a total of 88 columns which we treated as variables for the research. However, not all variables were used in the research we therefore had to do some data cleaning. Here is a preview of the variables in our raw data.\n [1] \u0026quot;user_id\u0026quot; \u0026quot;status_id\u0026quot; \u0026quot;created_at\u0026quot; [4] \u0026quot;screen_name\u0026quot; \u0026quot;text\u0026quot; \u0026quot;source\u0026quot; [7] \u0026quot;display_text_width\u0026quot; \u0026quot;reply_to_status_id\u0026quot; \u0026quot;reply_to_user_id\u0026quot; [10] \u0026quot;reply_to_screen_name\u0026quot; \u0026quot;is_quote\u0026quot; \u0026quot;is_retweet\u0026quot; [13] \u0026quot;favorite_count\u0026quot; \u0026quot;retweet_count\u0026quot; \u0026quot;hashtags\u0026quot; [16] \u0026quot;symbols\u0026quot; \u0026quot;urls_url\u0026quot; \u0026quot;urls_t.co\u0026quot; [19] \u0026quot;urls_expanded_url\u0026quot; \u0026quot;media_url\u0026quot; \u0026quot;media_t.co\u0026quot; [22] \u0026quot;media_expanded_url\u0026quot; \u0026quot;media_type\u0026quot; \u0026quot;ext_media_url\u0026quot; [25] \u0026quot;ext_media_t.co\u0026quot; \u0026quot;ext_media_expanded_url\u0026quot; \u0026quot;ext_media_type\u0026quot; [28] \u0026quot;mentions_user_id\u0026quot; \u0026quot;mentions_screen_name\u0026quot; \u0026quot;lang\u0026quot; [31] \u0026quot;quoted_status_id\u0026quot; \u0026quot;quoted_text\u0026quot; \u0026quot;quoted_created_at\u0026quot; [34] \u0026quot;quoted_source\u0026quot; \u0026quot;quoted_favorite_count\u0026quot; \u0026quot;quoted_retweet_count\u0026quot; [37] \u0026quot;quoted_user_id\u0026quot; \u0026quot;quoted_screen_name\u0026quot; \u0026quot;quoted_name\u0026quot; [40] \u0026quot;quoted_followers_count\u0026quot; \u0026quot;quoted_friends_count\u0026quot; \u0026quot;quoted_statuses_count\u0026quot; [43] \u0026quot;quoted_location\u0026quot; \u0026quot;quoted_description\u0026quot; \u0026quot;quoted_verified\u0026quot; [46] \u0026quot;retweet_status_id\u0026quot; \u0026quot;retweet_text\u0026quot; \u0026quot;retweet_created_at\u0026quot; [49] \u0026quot;retweet_source\u0026quot; \u0026quot;retweet_favorite_count\u0026quot; \u0026quot;retweet_retweet_count\u0026quot; [52] \u0026quot;retweet_user_id\u0026quot; \u0026quot;retweet_screen_name\u0026quot; \u0026quot;retweet_name\u0026quot; [55] \u0026quot;retweet_followers_count\u0026quot; \u0026quot;retweet_friends_count\u0026quot; \u0026quot;retweet_statuses_count\u0026quot; [58] \u0026quot;retweet_location\u0026quot; \u0026quot;retweet_description\u0026quot; \u0026quot;retweet_verified\u0026quot; [61] \u0026quot;place_url\u0026quot; \u0026quot;place_name\u0026quot; \u0026quot;place_full_name\u0026quot; [64] \u0026quot;place_type\u0026quot; \u0026quot;country\u0026quot; \u0026quot;country_code\u0026quot; [67] \u0026quot;geo_coords\u0026quot; \u0026quot;coords_coords\u0026quot; \u0026quot;bbox_coords\u0026quot; [70] \u0026quot;status_url\u0026quot; \u0026quot;name\u0026quot; \u0026quot;location\u0026quot; [73] \u0026quot;description\u0026quot; \u0026quot;url\u0026quot; \u0026quot;protected\u0026quot; [76] \u0026quot;followers_count\u0026quot; \u0026quot;friends_count\u0026quot; \u0026quot;listed_count\u0026quot; [79] \u0026quot;statuses_count\u0026quot; \u0026quot;favourites_count\u0026quot; \u0026quot;account_created_at\u0026quot; [82] \u0026quot;verified\u0026quot; \u0026quot;profile_url\u0026quot; \u0026quot;profile_expanded_url\u0026quot; [85] \u0026quot;account_lang\u0026quot; \u0026quot;profile_banner_url\u0026quot; \u0026quot;profile_background_url\u0026quot; [88] \u0026quot;profile_image_url\u0026quot; \r\n\r2.Data pre-processing.\rThis stage involved cleaning up our data by removing the unwanted columns/variables. We decided to do with a select few variables we thought would be most appropriate for our case study. We chose the following seven variables:\n\rText - This column contained the actual tweets text.\rVerified - whether or not the user is verified on twitter.\rProtected - Whether a user is or isn‚Äôt protected (Locked accounts).\rLocation - Based on our challenge stated in the figure above, this variable was our most important variable. Rows with NULL values for location simply meant that the specific user DID NOT GEOTAG their tweet.\rFollowers Count - Number of followers the user had.\rRetweet Verifie - Whether the tweet had been retweeted by a verified user or not.\rSource - Source of the tweet i.e ‚ÄúAndroid‚Äù, ‚Äúweb client‚Äù e.t.c\r\rCode for the data cleanup and variables setting that was done in Python can be found here.\n\n\r2.1 Re-importing Data in R and setting up for the Models\rAfter cleaning up the data, we imported it into R, the code chunk shows a preview of the top 4 rows of the input data.\n Text\r1074 Want to know how to optimize hyper-parameters in Caret with cost-specific functions? #rstats #datascience https://t.co/cupvirSXU9\r1316 via @RichardEudes - Quick Guide to R and Statistical Programming https://t.co/GfyhLMgiuB #analytics, #datascience, #rstats, #statistics https://t.co/Cx3TGJTOoI\r2636 small #rstats trick: if you need to know if a *sorted* variable is equally spaced (e.g., if it\u0026#39;s a contiguous sequence of ints, which was my use case) you can look at the characteristics of diff(x), e.g.\\n\\nsummary(diff(x))\\ntable(diff(x))\r2939 my #ggplot2 flipbook project is online! \u0026lt;U+0001F60E\u0026gt;\u0026lt;U+0001F913\u0026gt;\u0026lt;U+0001F913\u0026gt; Incrementally walks through plotting code (#MakeoverMonday, soon #TidyTuesday plots). Using #xaringan with reveal function; thanks, @statsgen @grrrck. #rstats. https://t.co/bBBzv0iZLw https://t.co/tFtD78IOHZ\rVerified Protected Location Followers VerifiedRetweet\r1074 FALSE FALSE Singapore 1570 FALSE\r1316 FALSE FALSE Paris, France 2151 NA\r2636 FALSE FALSE Pleasant Hill, CA 1207 NA\r2939 FALSE FALSE Sri Lanka 2623 FALSE\rCharacters\r1074 DS-retweet\r1316 IFTTT\r2636 Twitter Web Client\r2939 Twitter for Android\rWe still had to do some data pre-processing for the models which includes checking for and removing NULL values if present. Below is a sample table of the final data set used in the analysis.\n\r\rVerified\rProtected\rLocation\rFollowers\rVerifiedRetweet\rCharacters\r\r\r\rNO\rNO\rTAGGED\r\u0026gt;500\rYES\r55\r\rYES\rYES\rNON-TAGGED\r\u0026gt;500\rYES\r80\r\rNO\rNO\rTAGGED\r\u0026gt;500\rYES\r193\r\rNO\rNO\rTAGGED\r\u0026gt;500\rNO\r188\r\rYES\rNO\rTAGGED\r500\u0026lt;\rYES\r188\r\rNO\rNO\rNON-TAGGED\r500\u0026lt;\rNO\r190\r\r\r\rFrom the table above, we can observe a new column ‚ÄúCharacters‚Äù. This was an additional variable derived by counting the number of characters in the tweet text.\n\n\r3.Model Specifications\rDue to the nature of our problem,(we had several uncorrelated variables) we decided to do a classification analysis. This means we had to come up with a classifier model to regress n variables based on our dependent variable, the Location variable. The main challenge of classifier models is knowing what really goes on inside the models that leads to the final output. Even with higher levels of accuracy in some models, it is quite difficult o understand the paths of a given model. However, using Random forests and Decision Tree classifiers can give us a graphical representation of the criteria followed by the models to arrive at a given output. Another upper hand of decision tree models is that they require minimal data cleaning, less time consuming. Here is a detailed read on how decision trees work.\n\r\rCreating Train \u0026amp; Test Sets.\rFor the training and test data sets, we randomly split our data set into two sates. Usually, the best practice is to train the model with with a larger proportion of the data set. We therefore took 80% for training and 20% for test purposes.\n\n\rModel Training.\rWe trained our decision tree model to predict a class ‚Äúlocation‚Äù. Whether a location is geotagged or not geotagged based on whether the user is verified, protected, has over 500 followers, is retweeted by another verified user and the number of characters in their tweet. Bellow is the visual output of the trained model.\n\r\r\rFigure 2: The Tree\r\r\r\rWhen interpreting decision trees, you start at the root node. The root node is the one on top of the decision tree. Since what we want is those nodes with geotagged locations, it is safe to ignore the non-tagged nodes. Note that our highest entropy level was observed on one variable only, the number of characters in the tweet text. This might not always be the case with decision trees though, it is possible to have more than one factor. In such situations, it is best to run several decision trees to build a random forest and make a decision based on the most prevalent variables.\nFor our case, we only focus on what we found:\nAt the top node, we can see the overall probability of a user geotagging their tweets. 75 percent of the users in the training set geotagged their tweets. not\n\rOur second node asks whether the number of characters are more than 134 and goes to depth 2 where we can observe the highest number of users tweeted more than 134 characters at 80 percent with an 80 percent probability of geotagging their tweets.\n\rNode 3 checks if the number of characters in a tweet is less than 134. If yes, head to depth 3, where we can see that 20 percent of users had less than 134 characters with a 50 percent probability of geotagging their tweets.\n\rFinally, looking at depth 4 which originates from the node that checks is number of characters is equal to or more than 122, we can see that 12 percent of users had tweets with character equal to or more than 124, with 88 percent probability of geotagging their tweets.\n\r\r\n3.1 Model Testing and performance accuracy.\rWith our model trained and outputs observed, we were able to run a test with our test subset. Here is our confusion matrix.\n\r\rConfusion matrix\r predict_geotags\rNON-TAGGED TAGGED\rNON-TAGGED 90 248\rTAGGED 2 1043\r\n\rModel Accuracy\r\u0026gt; #performance\r\u0026gt; accuracy_Test \u0026lt;- sum(diag(table_mat)) / sum(table_mat)\r\u0026gt; print(paste(\u0026#39;Accuracy for test is\u0026#39;, accuracy_Test))\r[1] \u0026quot;Accuracy for test is 0.819233550253073\u0026quot;\rFrom the confusion matrix above, we can observe that the model had a true negative of 90 predictions. That is, 90 predictions were correctly predicted as not geotagged. A false positive of 248 predictions was observed where the model wrongly predicted 248 tweets were geotagged whereas in real sense they were not.\nFor the tagged tweets, we had a false negative of 2 predictions against a true positive of 1043 predictions. This means that our model was able to correctly predict 1043 geotagged tweets from the test data. The accuracy of the model turned out pretty good, at an 82 percent accuracy level. The theoretical formula for the accuracy is the proportion of true positives and the true negatives divided by the sum of the confusion matrix.\n\r\\[ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\\]\n\rFor a better accuracy level, the model‚Äôs hyper-parameters can be tweaked to improve performance. Another option is implementing a random forest test.\n\n4. Conclusion and Recommendation\rWith our decision tree model, we were able to attain a high level of accuracy for a model that test whether users with tweets containing characters equal to or above 122 are likely to geotag their tweets. Our nudge in this case is the number of characters in a tweet and precisely, 124 or more. Our recommendation therefore would be to encourage users to tweet longer or engage them in trending topics that require one to write more, for example a TT like # MyLifeHistoryInANutshell‚Ä¶-in the hope that a user will eventually geotag their tweet.\n\rCome to think of it, did twitter really increase the number of characters just for tweeps to tweet more and as they said, to get more people to join twitter? I have a theory, it was a NUDGE!\n\r\n\r\rReferences\rBusiness balls official website\n\rThaler, R.H., Sunstein, C.R., and Balz, J.P. Choice Architecture. SSRN Electronic Journal (2010), 1‚Äì18; https://ssrn.com/abstract=1583509\n\rThaler, R.H. and Sunstein, C.R. Nudge: Improving Decisions About Health, Wealth, and Happiness. Yale University Press, New Haven, CT, and London, U.K., 2008.\n\r\r\n\r\r\n\r","date":1550361600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576001886,"objectID":"5e38e10b1d59745f694d870909e17806","permalink":"/post/digital-nudging/","publishdate":"2019-02-17T00:00:00Z","relpermalink":"/post/digital-nudging/","section":"post","summary":"Introduction:\rHere‚Äôs a fun fact; An average human being (probably an adult) makes close to 30,000 conscious decisions every day. This isn‚Äôt entirely true though, in fact, I just made that number up. I could be right because if you think about it, how many decisions would you say you make on a day to day basis? Depending on who you are the above obviously varies widely and you know best.","tags":["Twitter","Data Mining","R","Python","Decision trees","regression"],"title":"Digital Nudging","type":"post"},{"authors":[],"categories":[],"content":"Welcome to Slides Academic\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three  A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/img/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567850988,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Carlvin J Mwange"],"categories":["Data Mining","R"],"content":"\rPart I\r\rThis first section assumes you have no knowledge in building a twitter app to be used for fetching data. You can skip directly to the second section here if you are able to build your own twitter app and get the required authentication keys.\n\r\rIntroduction:\rSocial media usage has grown rapidly over the past few decades. Most social networks we can think of now are so well established, making them a platform where people can not only interact but also a haven for anyone in need of ‚Äúunstructured‚Äù data. With an almost constant rate of increasing users each day, social networks such as Facebook and Twitter have become great sources of data which can be used in the broad field of Data Science:Talk of (those pretty annoying) targeted ads for example‚Ä¶\n\r\r\nWith the help of APIs, we are easily able to get data from such platforms to be used for further analysis.\rIn this article we will go through the preliminaries of text mining in R using Twitter data.\rThe main advantage of these APIs is that the data we will fetch comes in a well-structured format which makes our work easier when crunching.\rIn this case we will use the readily available Twitter API and create our own Twitter app that will then help in fetching the data.\n\n\rCreating a Twitter app\rTo create a twitter app we can use for fetching metadata, we first need to have a Twitter account. We then need to go to the twitter dev site and log in with our user account.\rOn the top right corner should be a drop down menu next to your username, go to APPS. At this point if you are doing this for the first time your Apps section should be blank. Click on ‚ÄúCreate an app‚Äù to‚Ä¶ create an app.\n\r\rWe then have to fill in the form below appropriately. Here is a breakdown of what‚Äôs required:\n\rName:\rGive your app a unique name of your choice, e.g UniqueName\rDescription:\rThis can always be changed later, use this to provide a brief note on what your app is all about to be able to distinguish it from other apps you might create in future.\rWebsite:\rThis should be your application‚Äôs home page web site. It is however not applicable for most personal apps. Anything goes here e.g https://carlvinjerry.github.io\rCallback URL:\rI would ignore the Callback URL field. If you are allowing users to log into your app to authenticate themselves, you‚Äôd enter the URL where they would be returned after they‚Äôve given permission to Twitter to use your app.\r\r\rApp details\n\r\r\nThe remaining fields should be quite straight forward but must be filled. Click ‚ÄúCreate‚Äù once done and there you have your first twitter app.\rOn your app is a menu with Keys and tokens. These are the most important components since we will need them to access data from the API.Generate both consumer and access tokens (if not readily available) and take note of them. NB: Keys are private property‚Ä¶most of the times\n\r\r\nThe final bit of setting up our twitter app is granting access permissions. We will mostly do fine with read-only if all we need is to fetch data but it can always be changed later.\n\r\r\nNow we can move on to the next step where we set up R to query data from Twitter.\n\n\nPart II\r\r\rSetting up R to fetch twitter data\rWith our twitter app set up in part I above and we are able to get the authentication keys for the API, we can now easily fetch data from twitter in R. The following steps will help us do this:\n\rdiv.blue { background-color:#e6f0ff; border-radius: 5px; padding: 20px;}\r\rPrerequisites:\r\rTwitter API Keys: At this point we already have our twitter app with the required API keys.\rR and an IDE of choice: We also need to have R installed, advisably the latest version. Microsoft‚Äôs enhanced R distribution is recommended over the\rbase R but for this specific task either can do just fine. I would recommend R STUDIO for an IDE. One obvious advantage of all these is that they‚Äôre open-source tools.\r\r\r\n\r1.Install and Load the required packages in R\rR has a standard set of packages, each with different tasks. You can find some packages for download\nhere. The code chunk below installs and loads the specific packages we need for this task. Take note of comments at each line of code, initiated by an octothorp.\n# Install packages\rinstall.packages(\u0026quot;twitteR\u0026quot;) #------Extracts data from twitter\rinstall.packages(\u0026quot;httr\u0026quot;) #--------Tools for Working with URLs and HTTP\r# We can now load the two packages\rlibrary(\u0026quot;twitteR\u0026quot;)\rrequire(\u0026quot;httr\u0026quot;) #-------------Both require() and library() can be used to call an installed package\r\nNB: Windows users might need to download a certification file and store it in the working directory. This certificate file initiates a handshake between R and the Twitter API.\n# Download \u0026quot;cacert.pem\u0026quot; file\rdownload.file(url = \u0026quot;https://curl.haxx.se/ca/cacert.pem\u0026quot;, destfile = \u0026quot;cacert.pem\u0026quot;)\r\n\r2.Create and store objects containing the twitter authenticated credentials\rThis is where we invoke the twitter API using the credentials from our app and query the data we need.\n# Authentication keys\rconsumer_key \u0026lt;- \u0026quot;hjksdha08097afnjhaa90uaf\u0026quot;\rconsumer_secret \u0026lt;- \u0026quot;hjksdha08097afnjhaa90uaf\u0026quot;\raccess_token \u0026lt;- \u0026quot;hjksdha08097afnjhaa90uaf\u0026quot;\raccess_secret \u0026lt;- \u0026quot;hjksdha08097afnjhaa90uaf\u0026quot;\r# The above tokens are what we made the twitter app for.\r\n\r3.Query data from twitter\rWe can now go ahead and fetch our data. Due to limitations on the twitter standard apps, it is advisable to store your data in R locally. This will reduce the number of times you have to make requests to fetch data. You will therefore do much more with your app that way regardless of the limitations- Or you can as well buy the premium rights. In my example below, I am fetching data for a user on twitter called @UKenyatta.\n# Connect to Twitter\rsetup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)\rtweets \u0026lt;- userTimeline(\u0026quot;UKenyatta\u0026quot;, n = 3200) # Standard twitter apps are limited to 3200 tweets per #download session. This could come out less depending on\r# the app\r# create a data frame of the tweets\rUKenyatta_Tweets \u0026lt;- tbl_df(map_df(tweets, as.data.frame))\r# Save tweets for later (and note when saved):\rsave(UKenyatta_Tweets, file = \u0026quot;UKenyatta_Tweets.RData\u0026quot;)\r# You can then access them later at will...\r# load(\u0026quot;UKenyatta_Tweets.RData\u0026quot;)\rYou can now manipulate your data and see what you find out‚Ä¶\n\n\r\r\n\r","date":1548374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576001886,"objectID":"5cdd7964d7776f553ac24d1fdeae48ad","permalink":"/post/data-mining/","publishdate":"2019-01-25T00:00:00Z","relpermalink":"/post/data-mining/","section":"post","summary":"Part I\r\rThis first section assumes you have no knowledge in building a twitter app to be used for fetching data. You can skip directly to the second section here if you are able to build your own twitter app and get the required authentication keys.\n\r\rIntroduction:\rSocial media usage has grown rapidly over the past few decades. Most social networks we can think of now are so well established, making them a platform where people can not only interact but also a haven for anyone in need of ‚Äúunstructured‚Äù data.","tags":["Twitter","Data Mining","R"],"title":"Twitter Data Mining In R","type":"post"},{"authors":["Carlvin J Mwange"],"categories":["Demo"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\nCheck out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n üëâ Get Started üìö View the documentation üí¨ Ask a question on the forum üë• Chat with the community üê¶ Twitter: @source_themes @GeorgeCushen #MadeWithAcademic üí° Request a feature or report a bug ‚¨ÜÔ∏è Updating? View the Update Guide and Release Notes ‚ù§ Support development of Academic:  ‚òïÔ∏è Donate a coffee üíµ Become a backer on Patreon üñºÔ∏è Decorate your laptop or journal with an Academic sticker üëï Wear the T-shirt üë©‚Äçüíª Contribute       Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567850988,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":["Carlvin J Mwange","Robert Ford"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567850988,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["Carlvin J Mwange","Robert Ford"],"categories":null,"content":"Supplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567850988,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]